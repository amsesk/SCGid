#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on Sat Dec  2 04:39:00 2017

@author: kevinamses
"""

'''
To calculate RSCU for a set of synonymous codons...
EX:
    SERINE,    N,    Calculation,    RSCU
    UCU,    13,    13/((1/6)*66),    1.18
    UCC,    2,    2/((1/6)*66),    0.18
    UCA,    4,    4/((1/6)*66),    0.36
    UCG,    11,    11/((1/6)*66),    1.00
    AGU,    26,    26/((1/6)*66),    0.18
    AGC,    10,    10/((1/6)*66),    2.36
   >SUM:    66,    66/((1/6)*66),    0.91

#ncbi = NCBITaxa()
#ncbi.update_taxonomy_database()
'''
#%%
import sys
import re
import os
import pandas as pd
import numpy as np
import operator
import argparse
import inspect
import subprocess
import settings
import cPickle as pickle
import shutil
from sequence import *
from ete3 import Tree, TreeStyle, NodeStyle, NCBITaxa
from lib import *
from infotable import infotable

#%% some specific functions that need to be generalized at some point and given a new home
def get_by_idx (row):
    ret = []
    for i in row.maxes:
        ret.append(row.lineage[i])
    return ret
def count_unique (l):
    if len(l) == 1:
        return l[0]
    else:
        counts = {}
        for ele in set(l):
            counts[l.count(ele)] = ele
        best = {c:ele for c,ele in counts.iteritems() if c == max(counts.keys())}
        if len(best.keys()) > 1:
            logger.critical("Too many best hits...write more code to deal with this.")
            sys.exit(-5)
        else:
            return best[best.keys()[0]]

#%%

bin_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))
pkg_home = os.path.dirname(bin_dir)
path_to_this_file = inspect.getfile(inspect.currentframe())
this_module = "codons"

parser = argparse.ArgumentParser()
parser.add_argument('-m','--gff3', metavar='gene_models', required = False, default = None, help ="A gff3 file from Augustus (one is generated by scgid blob) that contains the gene models for your metagenome.")
parser.add_argument('-n','--nucl', metavar='contig_fasta', required = True, help ="The contig fasta associated with your metagenome.")
parser.add_argument('-g', '--targets', metavar = 'target_taxa', action='store', required=True, help="A comma-separated list with NO spaces of the taxonomic levels that the gc-coverage window should be chosen with respect to including. EXAMPLE: '-g Fungi,Eukaryota,Homo'")
parser.add_argument('-x', '--exceptions', metavar = 'exceptions_to_target_taxa', action='store', required=False, default=None, help="A comma-separated list with NO spaces of any exlusions to the taxonomic levels specified in -g|--targets. For instance if you included Fungi in targets but want to exclude ascomycetes use: '-x Ascomycota'")
parser.add_argument('-f','--prefix', metavar = 'prefix_for_output', required=False, default='scgid', help="The prefix that you would like to be used for all output files. DEFAULT = scgid")
parser.add_argument('--cpus', metavar = 'cores', action = 'store', required = False, default = "1", help = "The number of cores available for BLAST to use.")
parser.add_argument('--mode', metavar = "mode", action="store",required=False, default ='blastp', help = "The type of blast results that you would like to use to annotate the tips of the RSCU tree ('blastp' or 'blastn'). This module will automatically do a blastn search of the NCBI nt database for you. At this time, a blastp search can not be run directly from this script. INSTEAD, if using mode 'blastp' (DEFAULT, recommended) you must specify a scgid blob-derived _info_table.tsv file with -i|--infotable")
parser.add_argument('--minsize', metavar = 'minsize', action = 'store', required = False, default = '3000', help = 'Minimum length of CDS concatenate to be kept and used to build RSCU tree. Highly fragmented assemblies will need this to be reduced. Reduce in response to `Tree too small.` error.')
parser.add_argument('-sp','--augustus_sp', metavar = "augustus_species", action="store",required=False, default=None, help = "Augustus species for gene predicition. Type `augustus --species=help` for list of available species designations.")
parser.add_argument('-e', '--evalue', metavar = 'e-value_cutoff', action = 'store', required = False, default = '1e-5', help = "The evalue cutoff for blast. Default: 1xe-5)")
parser.add_argument('-b','--blastout', metavar = "blastout", action="store",required=False, help = "The blast output file from a blastn search of the NCBI nt database with your contigs as query. If you have not done this yet, this script will do it for you.")
parser.add_argument('-i','--infotable', metavar = "infotable", action="store",required=False, help = "The scgid gc-cov-derived infotable generated by a blastp search of a swissprot-style protein database.")
parser.add_argument("--noplot", action="store_true", default=False, required=False, help="Turns of plotting of annotated trees to PDF.")
parser.add_argument('--Xmx', metavar = "available_memory", action="store",required=False, default = "2g", help = "Set memoray available to run ClaMs. Specicy as such: X megabytes = Xm, X gigabytes = Xg")
args = parser.parse_args()

prefix = args.prefix
nucl_path = os.path.abspath(args.nucl)

gff3 = args.gff3
blastout = args.blastout
info_table_path = args.infotable

if gff3 is not None:
    gff3 = os.path.abspath(gff3)
if blastout is not None:
    blastout = os.path.abspath(blastout)
if info_table_path is not None:
    info_table_path = os.path.abspath(info_table_path)

blastout_check = True
gff3_check = True

#%% navigate to head of working directory
try:
    os.chdir(args.prefix+'_scgid_output')
except:
    os.mkdir(args.prefix+'_scgid_output')
    os.chdir(args.prefix+'_scgid_output')

# Start logging now that we are in run working directory
logs = start_logging('codons',args, sys.argv)
logger = logs[0]
blogger = logs[1]

#%%
logger.info("Starting RSCU-based contig selection process.")

#Get targetting information from arguments
target_taxa = {}
target_taxa['target'] = args.targets.split(',')
if args.exceptions is None:
    target_taxa['exception'] = []
else:
    target_taxa['exception'] = args.exceptions.split(',')

#%% in the absense of -m|--gff3, see if a gff3 of predicted proteins was previously produced by gc_cov.py
if gff3 is None:
    gff3 = os.path.join(os.getcwd(),'rscu',prefix+'.aug.out.gff3') #check here first
    if not os.path.isfile(gff3):
        gff3 = os.path.join(os.getcwd(),'blob',prefix+'.aug.out.gff3') #check in blob next
        if not os.path.isfile(gff3):
            gff3 = os.path.join(os.getcwd(),'rscu',prefix+".nt.blast.out") #rename for blastn output cmd
            logger.info("Nothing given for -m|--gff3 and unable to locate augustus gff3 output file in default locations. Augustus will have to be run prior to RSCU-based genome selection.")
            gff3_check = False #Will have to run Augustus below
        else:
            logger.info("Found protein gff3: "+gff3+". Skipping augustus...")

else:
    if not os.path.isfile(gff3):
        #have to raise IOError, user provided a nonexistent file, gff3_check = False, in spirit but unecessary
        logger.critical("-m|--gff3: No such file or directory, "+gff3)
        raise IOError
    else:
        pass #gff3_check set to True by default


#%% see if nt.blast.out has been done for rscu or is present here in the esom folder under its default name
if args.mode not in ['blastn','blastp']:
    logger.critical("Invalid `--mode` specified, "+args.mode)
    raise ValueError

if args.mode == 'blastn':
    if blastout is None:
    #try to locate nt blastout in default locations
        blastout = os.path.join(os.getcwd(),'rscu',prefix+".nt.blast.out") #check here first
        if not os.path.isfile(blastout):
            blastout = os.path.join(os.getcwd(),'esom',prefix+".nt.blast.out") #check in esom next
            if not os.path.isfile(blastout):
                blastout = os.path.join(os.getcwd(),'rscu',prefix+".nt.blast.out") #rename for blastn output cmd
                logger.info("Nothing given for -b|--blastout and unable to locate nt blast output file in default locations. BLASTN search will have to be run prior to annotation.")
                blastout_check = False #Will have to run BLASTN below
            else:
                logger.info("Found blast output file: "+blastout+". Skipping BLAST...")

    else:
        if not os.path.isfile(blastout):
            #have to raise IOError, user provided a nonexistent file, blastout_check = False, in spirit but unecessary
            logger.critical("-b|--blastout: No such file or directory, "+blastout)
            raise IOError
        else:
            pass #blastout_check set to True by default
elif args.mode == 'blastp':
    if info_table_path is None:
        logger.critical("Use of `--mode blastp` required specification of -i|--infotable.")
        raise IOError

#%% navigate to rscu output directory
try:
    os.chdir('rscu')
except:
    os.mkdir('rscu')
    os.chdir('rscu')

#%% make a temp dir to deal with incomplete runs leaving incomplete files
if os.path.isdir('temp'):
    shutil.rmtree('temp')
    os.mkdir('temp')
    os.chdir('temp')
else:
    os.mkdir('temp')
    os.chdir('temp')

#%% Run Augustus if necessary
if not gff3_check:
    if args.augustus_sp is None:
        logger.critical("ERROR: -sp|--augustus_sp required for gene prediction.")
        raise ValueError
    to_do = ['1','0']
    arguments = ['-n',nucl_path,'-sp',args.augustus_sp,'-e',args.evalue,'-f',args.prefix,'-c',','.join(to_do)]
    call = os.path.join(bin_dir,'predict_and_blast.py')
    arguments.insert(0,call)
    py = sys.executable
    arguments.insert(0,py)
    subprocessC(arguments)

    ## move augustus outputs to default location if made successfully in temp
    shutil.copyfile(prefix+'.aug.out.gff3','../'+prefix+".aug.out.gff3")
    shutil.copyfile(prefix+'.aug.out.fasta','../'+prefix+".aug.out.fasta")

#%% BLASTN, if necessary ###
if args.mode == 'blastn':
    if not blastout_check:
        # Make sure that BLAST is available
        try:
            subprocessT(['blastn','-help'])
        except:
            logger.critical(IOError("BLAST is either not installed or unavailable."))
            raise IOError("BLAST is either not installed or unavailable.")

        logger.info("No blastn output file detected. Running blastn on contig file.")

        outfmt = "6 qseqid sseqid pident qlen length mismatch gapope evalue bitscore staxids"
        blastn_cmd = ["blastn","-query",nucl_path,"-max_target_seqs","1","-num_threads",args.cpus,"-db","nt","-outfmt", outfmt, "-evalue",args.evalue,"-out",blastout]
        logger.info(' '.join(blastn_cmd))
        subprocessP(blastn_cmd, logger)

        ## move blast.out to default location if made successfully in temp
        #shutil.copyfile(prefix+'.nt.blast.out','../'+prefix+".nt.blast.out")

    else:
        logger.info("Using previously created blast output file, "+blastout)

        best_out = ""
        taxids_out = ""
        if os.path.isfile(blastout+'.best') is False:
            for key,best in best_blast_hit(blastout).iteritems():

                ### Think that it's time to make all names the same between different modules ###
                #spl = best[0].split("_")
                #short_key = '_'.join(spl[0:2])
                #short_key = short_key.replace("NODE_","N")
                #best[0] = short_key

                best_out += '\t'.join(best)+'\n'
                taxids_out += best[0]+'\t'+best[8]+'\n'

            with open(os.path.split(blastout)[1]+'.best','w') as f:
                f.write(best_out)

            with open(os.path.split(blastout)[1]+'.best.taxids','w') as f:
                f.write(taxids_out)
        else:
            logger.info("Using these previously created blast-related output files:\n\t"+blastout+".best\n\t"+blastout+".best.taxids\n\n\t---- Remove to recalculate ----")


#%%
## Read in the nucleotide FASTA from pkl file or the original FASTA
nucl = pkl_fasta_in_out (nucl_path)

logger.info("Nucleotide FASTA read-in successfully.")

minsize = int(args.minsize)
cds_cat = extract_cds_gff3(gff3, nucl)
cds_cat_large = remove_small_sequences(cds_cat, minsize)

if len(cds_cat_large) < 30:
    logger.critical("Less than 30 CDS concatenates available for analysis. Exitting...")
    sys.exit(8)

with open('scgid_concat_large.fasta','w') as f:
    for cat in cds_cat_large:
        f.write(cat.outFasta()+"\n")
logger.info("Wrote large CDS concatenates (>{}bp) to {}".format(minsize, os.path.join(os.getcwd(),prefix+"_concat_large.fasta")))

#%% Count the codons in each CDS concatenate and put this information into a nested dictionary (a dictionary of dictionaries of contig codon counts)
codon_count_table = {}
for CDS_cat in cds_cat_large:
    codon_count_table[CDS_cat.label] = get_blank_codon_counts()
    pos = 0
    transcript = transcribe(CDS_cat.sequence)
    trans_comp = complement(transcript)
    num = len(trans_comp)/3
    for i in range(0,num):
        this_codon = trans_comp[pos:pos+3]
        if "N" in this_codon:
            continue
        codon_count_table[CDS_cat.label][this_codon] += 1
        pos+=3

#%%
## Now to calculate RSCU for each codon for each contig
codon_table = get_codon_table()
for acid in codon_table:
    for key in codon_count_table:
        grouped = [x for x in codon_count_table[key] if x in codon_table[acid]]
        total = 0
        for synco in grouped:
            total += codon_count_table[key][synco]
            codon_count_table[key][synco] = [codon_count_table[key][synco]]
        for synco in grouped:
            if total == 0:
                rscu = 0.00
            else:
                occurences = codon_count_table[key][synco][0]
                recip_n = 1.00/float(len(grouped))
                rscu = occurences/(recip_n*total)
            codon_count_table[key][synco].append(rscu)


#%% Now compute the RSCU distance matrix according to GCUA paper
mat = {}
i = 0
for key,val in codon_count_table.iteritems():
    mat[key] = []
    for codon,stats in codon_count_table[key].iteritems():
        #exclude codons for Trp, Met, and the three stop codons
        if codon in ['AUG','UAA','UAG','UGA','UGG']:
            continue
        mat[key].append(stats[1])

#%% Add the columns of the distance matrix into a list from left -> right
dist_mat = []
dist_mat.append(mat.keys())
for key,values in mat.iteritems():
    col = []
    for p in mat.keys():
        diff = map(operator.sub,mat[key],mat[p])
        diff = map(abs,diff)
        dist = sum(diff)/59 #59 codons with synonyms that aren't STOP codons
        col.append(round(dist,5))
    dist_mat.append(col)

#%% Shuffling some things around and geting the distance matrix into lower triangular format
dist_array = np.array(dist_mat)
cols = list(dist_mat[0])
cols.insert(0,"NODE")
frame = pd.DataFrame(dist_array,index=cols)
frame = frame.transpose()
frame = frame.set_index("NODE")

lowert = np.tril(frame)
mat = lowert.tolist()
lowert[np.triu_indices(lowert.shape[0], 1)] = np.nan
cols.pop(0)
dist_mat_to_nexus = pd.DataFrame(lowert, index=cols, columns=cols)

#%% Output the distance matrix into NEXUS format - this could probably be optional
logger.info("Contig-wise RSCU values and distances calculated. Writing distance matrix in NEXUS format to "+os.path.join(os.getcwd(),prefix+"_rscu_distmat.nex"))

# Output distance matrix in NEXUS FORMAT
header = ["#NEXUS","begin distances;","dimensions","ntax="+str(len(dist_mat)-1)+";","matrix"]
header = "\n".join(header)
trailer = ["\n;","END;"]
trailer = "\n".join(trailer)

with open(prefix+'_rscu_distmat.nex','w') as f:
    f.write(header)
    f.write("\n")

dist_mat_to_nexus.to_csv(prefix+'_rscu_distmat.nex',sep=' ',index = True, header = False, mode = 'a')

with open(prefix+'_rscu_distmat.nex','a') as f:
    f.write(trailer)

logger.info("Building tree...")

#%% Build the NJ tree with R since biopython takes FOREVER to read-in big trees

with open(prefix+'_rscu_distmat.csv','w') as f:
    dist_mat_to_nexus.to_csv(prefix+'_rscu_distmat.csv',sep=',',index = True, header = False, mode = 'w')

treefile = "{}_rscu_nj.tre".format(prefix)
cmd = [os.path.join(settings.path_to_Rscript,"Rscript"),"--vanilla",bin_dir+"/ape_nj.R",prefix+"_rscu_distmat.csv",treefile]
logger.info(' '.join(cmd))
subprocessP(cmd, logger)

logger.info("Wrote RSCU NJ tree as a Newick string to "+os.path.join(os.getcwd(),treefile))

#%% Read the newick string into ETE and then annotate the tips based on blastn
nj_tree = Tree(treefile)
#nj_tree = Tree("../amphi_adaptOnlyTrim_rscu_nj.tre")

if args.mode == 'blastp':
    info_table = infotable(target_taxa)
    info_table.load(info_table_path)
    info_table.parse_lineage()
    taxlvl = info_table.taxon_level(level=1)

    taxlvl = taxlvl.groupby("contig").agg({ "lineage": lambda x: ','.join(x).split(','),
        "evalue": lambda x: [e for e in x]
        })
    ### get all evalues equal to best evalues, and their indices
    taxlvl['maxes'] = taxlvl.evalue.apply(lambda x: [i for i,e in enumerate(x) if e == min(x)])

    ### match hits with the evalue for that hit
    taxlvl['maxtax'] = taxlvl.apply(get_by_idx, axis=1)

    ### Get best taxonomy based on counts of best evalue taxa
    taxlvl['decide'] = taxlvl['maxtax'].apply(count_unique)
    taxlvl_decisions = taxlvl[["decide"]]

    #print taxlvl_decisions
    #print taxlvl_decisions.shape
    #for row in taxlvl.itertuples():
    #    if len(row.decide.keys()) > 1:
    #        print row
    annotated_tree = annotate_tips_prot (nj_tree, target_taxa, info_table)
else:
    annotated_tree = annotate_tips(nj_tree, target_taxa, '{}.best.taxids'.format(blastout))

with open("{}_rscuTree_annot.csv".format(prefix),'w') as f:
    for l in [ [x.name, x.annotation] for x in annotated_tree.iter_leaves()]:
        try:
            l.insert(1,taxlvl_decisions.loc[l[0]].item())
        except:
            l.insert(1,'unclassified')
        l = [i.strip() for i in l]
        f.write("{}\n".format( ','.join(l) ))

circ = TreeStyle()
circ.scale=500
circ.min_leaf_separation=1
circ.mode="c"
circ.force_topology=True
circ.show_leaf_name = True

#annotated_tree.show(tree_style=circ)
#sys.exit()

## Print the tree to extended Newick string and draw picture to PDF
#annotated_tree.render(prefix+"_rscu_nj_annotated.pdf", tree_style=ts)
#annotated_tree.write(features = [], format = 0, outfile = prefix+"_rscu_nj_annotated.tre")
#logger.info("The taxon-annotated RSCU tree has been written to "+os.getcwd()+"/"+prefix+"_rscu_nj_annotated.tre")
#logger.info("A picture of the taxon-annotated RSCU tree has been written to "+os.getcwd()+"/"+prefix+"_rscu_nj_annotated.pdf")


#%% Find the best clade to use for training ClaMS
curr_best = 0.00
best = [] #"best" here means worth looking into, although it is going to include some real shitty trees
for n in annotated_tree.iter_descendants():
    if n.is_leaf():
        pass
    if len(n.get_leaves()) > 30:
        count_t = float(len([l for l in n if l.annotation == "target"]))
        count_nt = float(len([l for l in n if l.annotation == "nontarget"]))
        count_unclass = float(len([l for l in n if l.annotation == "unclassified"]))
        total_classified = float(count_t + count_nt)
        #print count_t, count_nt, count_unclass
        if total_classified == 0:
            continue
        measure = float( (count_t - count_nt) / total_classified )
        #print measure
        if measure > curr_best:
            n.add_feature("measure",measure)
            n.add_feature("leaves", len(n.get_leaves()))
            best.append(n)
    else:
        continue

#order trees in order of best measure
#best = [n for n in best if n.measure >= 0.90]
best = sorted(best, key=lambda x: x.measure, reverse=True)

if len(best) ==  0:
    logger.critical("Tree too small.")
    sys.exit(7)

#Bin trees based on common edges, or in other words look for sets of trees that aren't just nested within eachother from the list of best trees
#However, based on how it's written now, if a monophyletic clade is nested within another, some (likely) poorer quality clades will include both and lead to a node ending up in multiple bins, BUT hopefully selection of the best clade from each bin sorts this out
bins = {}
i=0 #index iterator to add additional bins
for p in best:
    n_bins = len(bins) #number of bins present on each iteration
    found_match = False
    for n in range(0,n_bins):
        for t in bins[n]:
            if len(p.compare(t)['common_edges']) != 0:
                bins[n].append(p)
                found_match = True
                break
    if not found_match:
        bins[i] = [p]
        i+=1
#Now go through each bin and find the best tree from that bin
best_trees_by_bin = []
for b in range(0,len(bins)):
    measures = [i.measure for i in bins[b]]
    leaves = [i.leaves for i in bins[b]]
    max_measure_indices = [i for i,v in enumerate(measures) if v == max(measures)]
    if len(max_measure_indices) == 1:
        best_idx = measures.index(max(measures))
        best_trees_by_bin.append(bins[b][best_idx])
    else:
        leaves_of_maxes = [v for i,v in enumerate(leaves) if i in max_measure_indices]
        max_leaves = max(leaves_of_maxes)
        best_idx = leaves.index(max_leaves)
        best_trees_by_bin.append(bins[b][best_idx])

#for i in best_trees_by_bin:
#    print i.leaves,"\t",i.measure
#Now compare the best trees from each bin to decide on a best tree (or set of best trees) for subsequent actions

max_measure = max([i.measure for i in best_trees_by_bin])
best_trees = [i for i in best_trees_by_bin if i.measure == max_measure]
if len(best_trees) > 1:
    max_leaves = max([i.leaves for i in best_trees_by_bin])
    best_trees = [i for i in best_trees if i.leaves == max_leaves]
    if len(best_trees) > 1:
        logger.info("More than one best tree detemined from codon analysis.")
    else:
        final_tree = best_trees[0]
    #for tree in best_trees:
        #tree.show(tree_style=circ)
else:
    final_tree = best_trees[0]
#final_tree.show(tree_style=circ)

''' hopefully this isn't necessary now that proteins are being used to annotate trees, but the functionality should still probably be there, it would have to higher up though during the selection of the list of best trees
if best is None:
    curr_best = 0.00
    logger.warning("Going to include unclassified leaves now...")
    for clade in clades:
        t_unclass_combined = clade['count_t']+clade['count_unclass']
        measure = (t_unclass_combined-clade['count_nt'])/(t_unclass_combined+clade['count_nt'])
        #print measure
        if measure > curr_best:
            curr_best = measure
            best = dict(clade)

if best is None:
    logger.critical("There is no best clade to train ClaMS at the set thresholds. Exiting...")
    raise ValueError
'''
#best['node'].show()

list_for_trainset = [s for s in nucl if s.shortname in final_tree.get_leaf_names()]
annotfile = "{}_rscuTree_annot.csv".format(prefix)
trainset_shortnames = [s.shortname for s in list_for_trainset]
for line in open(annotfile).readlines():
    row = map(str.strip, line.split(','))
    row_reformed = ','.join(row)
    if row[0] in trainset_shortnames:
        replace_line(annotfile, row_reformed, "{},trainset".format(row_reformed))
    else:
        replace_line(annotfile, row_reformed, "{},not_selected".format(row_reformed))


with open(prefix+"_trainset.fasta",'w') as f:
    for seq in list_for_trainset:
        f.write(seq.outFasta()+"\n")
trainset_fname = prefix+"_trainset.fasta"
with open('trainsets.tsv','w') as f:
    f.write("rscu_derived_ts1"+"\t")
    f.write(trainset_fname)

### Generate file visualizing annotated tree showing in R
if not args.noplot:
    cmd = [os.path.join(settings.path_to_Rscript,"Rscript"),"--vanilla",os.path.join(bin_dir,"codons_phytools.R"), treefile, annotfile, "{}_annotated_tree.pdf".format(prefix)]
    logger.info(' '.join(cmd))
    subprocessP(cmd, logger)

logger.info("ClaMS trainset written to "+os.getcwd()+"/"+prefix+"_trainset.fasta")

#%% run ClaMS
logger.info("Running ClaMs...")
clams_cmd = ["java",'-Xmx'+args.Xmx,"-jar",os.path.join(settings.clams_path,"ClaMS-CLI.jar"),os.path.join(os.getcwd(),"trainsets.tsv"),nucl_path, prefix+"_clams_out","DBC","2","0.01217181"]
logger.info(' '.join(clams_cmd))
subprocessP(clams_cmd, logger)


#%% decide on the final genome and print it
to_include = []
count = 0
for line in open(prefix+"_clams_out").readlines():
    spl = line.split("\t")
    spl = map(str.strip,spl)
    if spl[1] == "rscu_derived_ts1":
        count += 1
        to_include.append(spl[0])
logger.info("ClaMs done, "+str(count)+" matches to trainset detected.")

final_genome = [s for s in nucl if s.label in to_include]
draft_genome_size = 0
for s in final_genome:
    with open(prefix+'_rscu_final_genome.fasta','a') as f:
        draft_genome_size += s.length
        f.write(s.outFasta()+"\n")

logger.info("RSCU draft genome comprised of "+str(draft_genome_size)+" nucleotides on "+str(len(final_genome))+
            " scaffolds. Draft genome printed to "+os.path.join(os.getcwd(),prefix+'_rscu_final_genome.fasta'))

## If you've gotten here, then everything should have worked, move everything from temp to ../ and change dir and delete temp
for f in os.listdir('.'):
    os.rename(f,"../"+f)
os.chdir("../")
os.rmdir("temp")
